{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Environment setup"
      ],
      "metadata": {
        "id": "e38QTaH9luBW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5Tq2sgVlijV"
      },
      "outputs": [],
      "source": [
        "pip install pandas tweepy snscrape==0.7.0.20230622 google-news-api pytrends google_trends pandas_gbq duckdb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 Code snippets by data source\n",
        "\n",
        "3.1 Social-media firehose → DataFrame"
      ],
      "metadata": {
        "id": "vhjyBhqEnKL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import snscrape.modules.twitter as sntw\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "QUERY = \"HDFC Bank lang:en since:2025-06-01 until:2025-07-01\"\n",
        "\n",
        "tweets = []\n",
        "for i, tweet in enumerate(sntw.TwitterSearchScraper(QUERY).get_items()):\n",
        "    if i == 10_000:          # quick demo cap\n",
        "        break\n",
        "    tweets.append({\n",
        "        \"tweet_id\": tweet.id,\n",
        "        \"ts_utc\": tweet.date,\n",
        "        \"user\": tweet.user.username,\n",
        "        \"text\": tweet.content,\n",
        "        \"reply_ct\": tweet.replyCount,\n",
        "        \"rt_ct\": tweet.retweetCount,\n",
        "        \"fav_ct\": tweet.likeCount,\n",
        "    })\n",
        "\n",
        "tw_df = pd.DataFrame(tweets).set_index(\"ts_utc\").sort_index()\n"
      ],
      "metadata": {
        "id": "b42H3jwCmxem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "tw_df[\"vader\"] = tw_df[\"text\"].map(lambda t: sia.polarity_scores(t)[\"compound\"])\n",
        "hourly = tw_df[\"vader\"].resample(\"1H\").mean()\n"
      ],
      "metadata": {
        "id": "bQ_jU6xBnO32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2 Professional news feed → DataFrame"
      ],
      "metadata": {
        "id": "XO0SShzqny80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gnews import GNews   # Google News wrapper\n",
        "gn = GNews(lang=\"en\", max_results=100, start_date=(2025,6,1), end_date=(2025,7,1))\n",
        "news_items = gn.get_news(\"HDFC Bank\")\n",
        "\n",
        "news_df = (\n",
        "    pd.DataFrame(news_items)\n",
        "      .assign(published=lambda d: pd.to_datetime(d[\"published date\"]))\n",
        "      .rename(columns={\"title\":\"headline\", \"description\":\"snippet\"})\n",
        "      .set_index(\"published\")\n",
        "      .sort_index()\n",
        ")\n"
      ],
      "metadata": {
        "id": "4YV94zK1npMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.3 Search Volume Index (Google Trends) → DataFrame\n"
      ],
      "metadata": {
        "id": "S8aAMRVon5mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytrends.request import TrendReq\n",
        "pytrends = TrendReq(hl='en-US', tz=330)   # India (UTC+5:30)\n",
        "kw_list = [\"HDFC Bank\"]\n",
        "pytrends.build_payload(kw_list, timeframe='2025-06-01 2025-07-01', geo='IN')\n",
        "gtrend_df = (\n",
        "    pytrends.interest_over_time()\n",
        "             .drop(columns=\"isPartial\")\n",
        "             .rename(columns={\"HDFC Bank\":\"gtrend\"})\n",
        ")\n"
      ],
      "metadata": {
        "id": "QoI7BRBRn2du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4 Structuring & stitching the pieces together"
      ],
      "metadata": {
        "id": "KOSrkR_cn-yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Align to hourly buckets to merge cleanly\n",
        "def to_hourly(df, col):\n",
        "    return df[col].resample(\"1H\").mean().to_frame()\n",
        "\n",
        "panel = (\n",
        "    to_hourly(tw_df, \"vader\")\n",
        "      .join(to_hourly(news_df, \"headline\").rename(columns={\"headline\":\"news_ct\"}))\n",
        "      .join(to_hourly(gtrend_df, \"gtrend\"))\n",
        "      .fillna(0)\n",
        ")\n",
        "\n",
        "panel.head()\n"
      ],
      "metadata": {
        "id": "Cv9dEMA3oBA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. exploratory data analysis of sample data ##"
      ],
      "metadata": {
        "id": "RxbmCO3woCkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import zscore\n",
        "\n",
        "\n",
        "def generate_data(seed: int = 42) -> pd.DataFrame:\n",
        "    \"\"\"Generate synthetic behavioural signals for June 2025.\"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    dates = pd.date_range(\"2025-06-01\", \"2025-06-30\", freq=\"D\")\n",
        "\n",
        "    # Social media sentiment: baseline noise around neutral\n",
        "    sentiment = rng.normal(loc=0.0, scale=0.1, size=len(dates))\n",
        "\n",
        "    # News count: Poisson with many zeros (weekends will get zero later)\n",
        "    news_count = rng.poisson(lam=1.0, size=len(dates))\n",
        "\n",
        "    # Search interest: gradually rising baseline\n",
        "    svi = np.clip(rng.normal(loc=40, scale=10, size=len(dates)), a_min=0, a_max=None)\n",
        "\n",
        "    # Inject a major positive event on 2025-06-25\n",
        "    event_date = pd.Timestamp(\"2025-06-25\")\n",
        "    idx_event = dates.get_loc(event_date)\n",
        "\n",
        "    sentiment[idx_event] = 0.71           # large positive sentiment\n",
        "    news_count[idx_event] = 20            # surge in coverage\n",
        "    svi[idx_event] = 100                  # peak search interest\n",
        "\n",
        "    # Elevated follow‑up day (optional realism)\n",
        "    if idx_event + 1 < len(dates):\n",
        "        sentiment[idx_event + 1] = np.clip(sentiment[idx_event + 1] + 0.15, -1, 1)\n",
        "        news_count[idx_event + 1] = max(news_count[idx_event + 1], 5)\n",
        "        svi[idx_event + 1] = max(svi[idx_event + 1], 76)\n",
        "\n",
        "    # Set news_count to zero on weekends\n",
        "    is_weekend = dates.weekday >= 5  # Sat/Sun are 5,6\n",
        "    news_count[is_weekend] = 0\n",
        "\n",
        "    df = pd.DataFrame(\n",
        "        {\n",
        "            \"sentiment\": sentiment,\n",
        "            \"news_count\": news_count,\n",
        "            \"svi\": svi,\n",
        "        },\n",
        "        index=dates,\n",
        "    )\n",
        "    return df\n",
        "\n",
        "\n",
        "def eda(df: pd.DataFrame) -> None:\n",
        "    \"\"\"Run exploratory data analysis and save outputs.\"\"\"\n",
        "    print(\"Summary statistics:\\n\", df.describe())\n",
        "\n",
        "    print(\"\\nPairwise correlations:\\n\", df.corr(method=\"pearson\"))\n",
        "\n",
        "    # Time‑series plots\n",
        "    fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(11, 12), sharex=True)\n",
        "\n",
        "    df[\"sentiment\"].plot(ax=axes[0], title=\"Daily Social Sentiment (VADER compound)\")\n",
        "    axes[0].axvline(pd.Timestamp(\"2025-06-25\"), linestyle=\"--\", label=\"Event\")\n",
        "    axes[0].legend()\n",
        "\n",
        "    df[\"news_count\"].plot(\n",
        "        ax=axes[1], title=\"Daily News Article Count\", kind=\"bar\"\n",
        "    )\n",
        "    axes[1].axvline(pd.Timestamp(\"2025-06-25\"), linestyle=\"--\")\n",
        "\n",
        "    df[\"svi\"].plot(ax=axes[2], title=\"Daily Google Search Volume Index (SVI)\")\n",
        "    axes[2].axvline(pd.Timestamp(\"2025-06-25\"), linestyle=\"--\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    fig.savefig(\"behavioural_signals_timeseries.png\")\n",
        "    plt.close(fig)\n",
        "\n",
        "    # Histograms\n",
        "    fig2 = df.hist(bins=10, figsize=(11, 4), layout=(1, 3))\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"behavioural_signals_histograms.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Outlier detection\n",
        "    z_scores = np.abs(zscore(df))\n",
        "    outliers = df[(z_scores > 3).any(axis=1)]\n",
        "    if not outliers.empty:\n",
        "        print(\"\\nOutlier days (z‑score > 3 on any signal):\")\n",
        "        print(outliers)\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    df = generate_data()\n",
        "    csv_path = \"behavioural_signals_june2025.csv\"\n",
        "    df.to_csv(csv_path, index_label=\"date\")\n",
        "    print(f\"Dataset saved to {csv_path}\")\n",
        "    eda(df)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G5DbRe8pHdT",
        "outputId": "faeca473-0e38-4e19-93bc-aa5b9d96f34d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset saved to behavioural_signals_june2025.csv\n",
            "Summary statistics:\n",
            "        sentiment  news_count         svi\n",
            "count  30.000000   30.000000   30.000000\n",
            "mean    0.031776    1.266667   40.889635\n",
            "std     0.150741    3.703990   15.309668\n",
            "min    -0.195104    0.000000   22.726796\n",
            "25%    -0.028340    0.000000   32.035401\n",
            "50%     0.033508    0.000000   38.480385\n",
            "75%     0.077096    1.000000   44.721928\n",
            "max     0.710000   20.000000  100.000000\n",
            "\n",
            "Pairwise correlations:\n",
            "             sentiment  news_count       svi\n",
            "sentiment    1.000000    0.813361  0.655289\n",
            "news_count   0.813361    1.000000  0.767012\n",
            "svi          0.655289    0.767012  1.000000\n",
            "\n",
            "Outlier days (z‑score > 3 on any signal):\n",
            "            sentiment  news_count    svi\n",
            "2025-06-25       0.71          20  100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-XSYPC3pwwB2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}